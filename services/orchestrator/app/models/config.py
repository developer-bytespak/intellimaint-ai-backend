"""LLM model configurations"""

MODEL_CONFIGS = {
    "gpt-4": {
        "max_tokens": 4096,
        "temperature": 0.7,
    },
    "claude-3": {
        "max_tokens": 4096,
        "temperature": 0.7,
    }
}

